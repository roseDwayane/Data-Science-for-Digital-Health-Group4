{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe72a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9587dc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>dod</th>\n",
       "      <th>gender</th>\n",
       "      <th>admission_age</th>\n",
       "      <th>hematocrit_min</th>\n",
       "      <th>hematocrit_max</th>\n",
       "      <th>hemoglobin_min</th>\n",
       "      <th>...</th>\n",
       "      <th>resp_rate_mean</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>temperature_mean</th>\n",
       "      <th>spo2_min</th>\n",
       "      <th>spo2_max</th>\n",
       "      <th>spo2_mean</th>\n",
       "      <th>glucose_min</th>\n",
       "      <th>glucose_max</th>\n",
       "      <th>glucose_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19452423</td>\n",
       "      <td>33252269</td>\n",
       "      <td>28656889</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>59</td>\n",
       "      <td>21.4</td>\n",
       "      <td>25.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>...</td>\n",
       "      <td>12.555556</td>\n",
       "      <td>36.50</td>\n",
       "      <td>36.89</td>\n",
       "      <td>36.667143</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>151.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>163.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18607896</td>\n",
       "      <td>34323529</td>\n",
       "      <td>21419235</td>\n",
       "      <td>0</td>\n",
       "      <td>2129-09-01</td>\n",
       "      <td>M</td>\n",
       "      <td>59</td>\n",
       "      <td>28.4</td>\n",
       "      <td>30.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>...</td>\n",
       "      <td>16.760000</td>\n",
       "      <td>35.72</td>\n",
       "      <td>36.44</td>\n",
       "      <td>36.146667</td>\n",
       "      <td>88.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.600000</td>\n",
       "      <td>135.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19655491</td>\n",
       "      <td>32465570</td>\n",
       "      <td>23321342</td>\n",
       "      <td>1</td>\n",
       "      <td>2173-06-14</td>\n",
       "      <td>F</td>\n",
       "      <td>55</td>\n",
       "      <td>14.1</td>\n",
       "      <td>30.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>17.092593</td>\n",
       "      <td>35.17</td>\n",
       "      <td>36.39</td>\n",
       "      <td>35.806250</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.259259</td>\n",
       "      <td>76.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>103.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10666659</td>\n",
       "      <td>35745198</td>\n",
       "      <td>23457167</td>\n",
       "      <td>1</td>\n",
       "      <td>2143-12-02</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>20.615385</td>\n",
       "      <td>35.56</td>\n",
       "      <td>36.67</td>\n",
       "      <td>35.977143</td>\n",
       "      <td>93.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>95.347826</td>\n",
       "      <td>76.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>92.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12668169</td>\n",
       "      <td>31574288</td>\n",
       "      <td>23898774</td>\n",
       "      <td>1</td>\n",
       "      <td>2156-08-19</td>\n",
       "      <td>M</td>\n",
       "      <td>54</td>\n",
       "      <td>21.8</td>\n",
       "      <td>23.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>...</td>\n",
       "      <td>21.472973</td>\n",
       "      <td>34.40</td>\n",
       "      <td>36.89</td>\n",
       "      <td>36.075714</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.540541</td>\n",
       "      <td>85.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>95.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   stay_id   hadm_id  hospital_expire_flag         dod gender  \\\n",
       "0    19452423  33252269  28656889                     0         NaN      M   \n",
       "1    18607896  34323529  21419235                     0  2129-09-01      M   \n",
       "2    19655491  32465570  23321342                     1  2173-06-14      F   \n",
       "3    10666659  35745198  23457167                     1  2143-12-02      F   \n",
       "4    12668169  31574288  23898774                     1  2156-08-19      M   \n",
       "\n",
       "   admission_age  hematocrit_min  hematocrit_max  hemoglobin_min  ...  \\\n",
       "0             59            21.4            25.6             7.2  ...   \n",
       "1             59            28.4            30.7             9.6  ...   \n",
       "2             55            14.1            30.5             4.6  ...   \n",
       "3             53            26.0            31.9             8.5  ...   \n",
       "4             54            21.8            23.1             7.6  ...   \n",
       "\n",
       "   resp_rate_mean  temperature_min  temperature_max  temperature_mean  \\\n",
       "0       12.555556            36.50            36.89         36.667143   \n",
       "1       16.760000            35.72            36.44         36.146667   \n",
       "2       17.092593            35.17            36.39         35.806250   \n",
       "3       20.615385            35.56            36.67         35.977143   \n",
       "4       21.472973            34.40            36.89         36.075714   \n",
       "\n",
       "   spo2_min  spo2_max   spo2_mean  glucose_min  glucose_max  glucose_mean  \n",
       "0     100.0     100.0  100.000000        151.0        180.0    163.800000  \n",
       "1      88.0     100.0   94.600000        135.0        178.0    160.000000  \n",
       "2      98.0     100.0   99.259259         76.0        144.0    103.750000  \n",
       "3      93.0      99.0   95.347826         76.0        109.0     92.500000  \n",
       "4      90.0     100.0   96.540541         85.0        103.0     95.666667  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('./clinicalData2.csv')\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b5c6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "      <th>gender</th>\n",
       "      <th>admission_age</th>\n",
       "      <th>hematocrit_min</th>\n",
       "      <th>hematocrit_max</th>\n",
       "      <th>hemoglobin_min</th>\n",
       "      <th>hemoglobin_max</th>\n",
       "      <th>platelets_min</th>\n",
       "      <th>platelets_max</th>\n",
       "      <th>wbc_min</th>\n",
       "      <th>...</th>\n",
       "      <th>resp_rate_mean</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>temperature_mean</th>\n",
       "      <th>spo2_min</th>\n",
       "      <th>spo2_max</th>\n",
       "      <th>spo2_mean</th>\n",
       "      <th>glucose_min</th>\n",
       "      <th>glucose_max</th>\n",
       "      <th>glucose_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>59</td>\n",
       "      <td>21.4</td>\n",
       "      <td>25.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.555556</td>\n",
       "      <td>36.50</td>\n",
       "      <td>36.89</td>\n",
       "      <td>36.667143</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>151.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>163.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>59</td>\n",
       "      <td>28.4</td>\n",
       "      <td>30.7</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>83.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>...</td>\n",
       "      <td>16.760000</td>\n",
       "      <td>35.72</td>\n",
       "      <td>36.44</td>\n",
       "      <td>36.146667</td>\n",
       "      <td>88.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.600000</td>\n",
       "      <td>135.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>160.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>55</td>\n",
       "      <td>14.1</td>\n",
       "      <td>30.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10.9</td>\n",
       "      <td>81.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>...</td>\n",
       "      <td>17.092593</td>\n",
       "      <td>35.17</td>\n",
       "      <td>36.39</td>\n",
       "      <td>35.806250</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.259259</td>\n",
       "      <td>76.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>103.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>26.0</td>\n",
       "      <td>31.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>163.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>...</td>\n",
       "      <td>20.615385</td>\n",
       "      <td>35.56</td>\n",
       "      <td>36.67</td>\n",
       "      <td>35.977143</td>\n",
       "      <td>93.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>95.347826</td>\n",
       "      <td>76.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>92.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>54</td>\n",
       "      <td>21.8</td>\n",
       "      <td>23.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>...</td>\n",
       "      <td>21.472973</td>\n",
       "      <td>34.40</td>\n",
       "      <td>36.89</td>\n",
       "      <td>36.075714</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.540541</td>\n",
       "      <td>85.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>95.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hospital_expire_flag gender  admission_age  hematocrit_min  hematocrit_max  \\\n",
       "0                     0      M             59            21.4            25.6   \n",
       "1                     0      M             59            28.4            30.7   \n",
       "2                     1      F             55            14.1            30.5   \n",
       "3                     1      F             53            26.0            31.9   \n",
       "4                     1      M             54            21.8            23.1   \n",
       "\n",
       "   hemoglobin_min  hemoglobin_max  platelets_min  platelets_max  wbc_min  ...  \\\n",
       "0             7.2             8.6           87.0          124.0      8.1  ...   \n",
       "1             9.6             9.8           83.0          102.0      8.7  ...   \n",
       "2             4.6            10.9           81.0          146.0      8.9  ...   \n",
       "3             8.5             8.5          163.0          173.0     15.8  ...   \n",
       "4             7.6             8.1           64.0           98.0     10.5  ...   \n",
       "\n",
       "   resp_rate_mean  temperature_min  temperature_max  temperature_mean  \\\n",
       "0       12.555556            36.50            36.89         36.667143   \n",
       "1       16.760000            35.72            36.44         36.146667   \n",
       "2       17.092593            35.17            36.39         35.806250   \n",
       "3       20.615385            35.56            36.67         35.977143   \n",
       "4       21.472973            34.40            36.89         36.075714   \n",
       "\n",
       "   spo2_min  spo2_max   spo2_mean  glucose_min  glucose_max  glucose_mean  \n",
       "0     100.0     100.0  100.000000        151.0        180.0    163.800000  \n",
       "1      88.0     100.0   94.600000        135.0        178.0    160.000000  \n",
       "2      98.0     100.0   99.259259         76.0        144.0    103.750000  \n",
       "3      93.0      99.0   95.347826         76.0        109.0     92.500000  \n",
       "4      90.0     100.0   96.540541         85.0        103.0     95.666667  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = data.drop(columns=['subject_id', 'stay_id', 'hadm_id', 'hospital_expire_flag'])\n",
    "X = data.drop(columns=['subject_id', 'stay_id', 'hadm_id', 'dod'])\n",
    "#X = X.fillna(X.mean())\n",
    "X = X.fillna(-1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8368ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data.drop('target', axis=1).values\n",
    "#X = data.drop(columns=['subject_id', 'stay_id', 'hadm_id', 'hospital_expire_flag', 'subject_id_1'])\n",
    "#X = X.fillna(X.mean())\n",
    "le = LabelEncoder()\n",
    "X['gender'] = le.fit_transform(X['gender'])\n",
    "#y = data['target'].values\n",
    "y = data['dod'].notnull().astype(int)\n",
    "#y = data['hospital_expire_flag']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "#for data, targets in train_loader:\n",
    "#    print(data, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1560ad4c",
   "metadata": {},
   "source": [
    "## data2vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0431d50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousModel(nn.Module):\n",
    "    def __init__(self, num_features, output_dim, dropout=0.0):\n",
    "        super(ContinuousModel, self).__init__()\n",
    "        #self.fc = nn.Linear(num_features, output_dim)\n",
    "        self.w_1 = nn.Linear(num_features, output_dim)\n",
    "        self.w_2 = nn.Linear(output_dim, num_features)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.fc(x)\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "# Example usage\n",
    "num_features = 112  # Number of input features\n",
    "output_dim = 1000     # Size of the output vector\n",
    "\n",
    "data2vector = ContinuousModel(num_features, output_dim)\n",
    "#input_data = torch.randn(1, num_features)  # Example input\n",
    "#vector = data2vector(input_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049fbbcc",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cba840f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_feature, 64)  # 112 features\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "model = BinaryClassifier(n_feature=num_features)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a8cf7c",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29591755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cnelabai/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/cnelabai/anaconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class ResNetTabular(nn.Module):\n",
    "    def __init__(self, num_features, num_classes=1):\n",
    "        super(ResNetTabular, self).__init__()\n",
    "        # Load a pre-trained ResNet model\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.resnet.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1).unsqueeze(2)\n",
    "        x = self.resnet(x)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "model = ResNetTabular(num_features=X_train.shape[1])\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8525b06",
   "metadata": {},
   "source": [
    "## UNet-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13293c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels, ks=7):\n",
    "        super().__init__()\n",
    "        padding = int((ks - 1) / 2)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv1d(in_channels, middle_channels, kernel_size=ks, padding=padding)\n",
    "        self.bn1 = nn.BatchNorm1d(middle_channels)\n",
    "        self.conv2 = nn.Conv1d(middle_channels, out_channels, kernel_size=ks, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=1, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        nb_filter = [32, 64, 128, 256, 512]\n",
    "\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        #self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='linear', align_corners=False)\n",
    "\n",
    "        # input_channel => 32; 32 => 64; 64=>128; 128=>256\n",
    "        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])\n",
    "        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])\n",
    "        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(512, 64)  # 112 features\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        #self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n",
    "        #self.conv2_2 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "        #self.conv1_3 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        #self.conv0_4 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "\n",
    "        #self.final = nn.Conv1d(nb_filter[0], num_classes, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        #print(x.shape)\n",
    "        x0_0 = self.conv0_0(x)\n",
    "        #print(x0_0.shape)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        #print(x1_0.shape)\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        #print(x2_0.shape)\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        #print(x3_0.shape)\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        #print(x4_0.shape)\n",
    "        x_pool = self.adaptive_pool(x4_0)\n",
    "        #print(x_pool.shape)\n",
    "        x_flattened = x_pool.view(x_pool.size(0), -1)\n",
    "        #print(x_flattened.shape)\n",
    "        x = torch.relu(self.fc1(x_flattened))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        output = self.sigmoid(self.fc3(x))\n",
    "        #x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        #x2_2 = self.conv2_2(torch.cat([x2_0, self.up(x3_0)], 1))\n",
    "        #x1_3 = self.conv1_3(torch.cat([x1_0, self.up(x2_2)], 1))\n",
    "        #x0_4 = self.conv0_4(torch.cat([x0_0, self.up(x1_3)], 1))\n",
    "\n",
    "        #output = self.final(x0_4)\n",
    "        return output\n",
    "\n",
    "model = UNet(num_classes=1)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2454cae0",
   "metadata": {},
   "source": [
    "## UNet (1 Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "279af314",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(UNet, self).__init__()\n",
    "        # Contracting Path (Encoder)\n",
    "        self.enc_conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n",
    "        self.enc_conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "\n",
    "        # Expanding Path (Decoder)\n",
    "        self.dec_conv1 = nn.Conv1d(32, 16, kernel_size=3, padding=1)\n",
    "        self.dec_conv2 = nn.Conv1d(16, 1, kernel_size=3, padding=1)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(num_features, 1)  # Adjust the size as needed\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Adding a channel dimension\n",
    "\n",
    "        # Encoder\n",
    "        x1 = self.pool(torch.relu(self.enc_conv1(x)))\n",
    "        x2 = self.pool(torch.relu(self.enc_conv2(x1)))\n",
    "\n",
    "        # Decoder\n",
    "        x3 = self.upsample(x2)\n",
    "        x3 = torch.relu(self.dec_conv1(x3))\n",
    "        x4 = self.upsample(x3)\n",
    "        x4 = torch.relu(self.dec_conv2(x4))\n",
    "\n",
    "        # Flatten and pass through the output layer\n",
    "        x4 = x4.squeeze(1)  # Removing the channel dimension\n",
    "        x4 = x4.view(x4.size(0), -1)  # Flatten\n",
    "        out = torch.sigmoid(self.output_layer(x4))\n",
    "\n",
    "        return out\n",
    "\n",
    "model = UNet(num_features=X_train.shape[1])\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fae04cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassifier(\n",
       "  (fc1): Linear(in_features=112, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data2vector.to(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa97eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.0634\n",
      "Epoch [2/100], Loss: 0.1601\n",
      "Epoch [3/100], Loss: 0.2643\n",
      "Epoch [4/100], Loss: 0.1839\n",
      "Epoch [5/100], Loss: 0.3669\n",
      "Epoch [6/100], Loss: 0.2578\n",
      "Epoch [7/100], Loss: 0.1525\n",
      "Epoch [8/100], Loss: 0.1104\n",
      "Epoch [9/100], Loss: 0.1544\n",
      "Epoch [10/100], Loss: 0.1439\n",
      "Epoch [11/100], Loss: 0.3241\n",
      "Epoch [12/100], Loss: 0.1142\n",
      "Epoch [13/100], Loss: 0.0940\n",
      "Epoch [14/100], Loss: 0.1782\n",
      "Epoch [15/100], Loss: 0.1085\n",
      "Epoch [16/100], Loss: 0.0998\n",
      "Epoch [17/100], Loss: 0.1650\n",
      "Epoch [18/100], Loss: 0.0964\n",
      "Epoch [19/100], Loss: 0.1598\n",
      "Epoch [20/100], Loss: 0.1262\n",
      "Epoch [21/100], Loss: 0.2685\n",
      "Epoch [22/100], Loss: 0.0664\n",
      "Epoch [23/100], Loss: 0.1409\n",
      "Epoch [24/100], Loss: 0.2217\n",
      "Epoch [25/100], Loss: 0.1245\n",
      "Epoch [26/100], Loss: 0.1545\n",
      "Epoch [27/100], Loss: 0.1300\n",
      "Epoch [28/100], Loss: 0.2351\n",
      "Epoch [29/100], Loss: 0.0997\n",
      "Epoch [30/100], Loss: 0.1018\n",
      "Epoch [31/100], Loss: 0.0972\n",
      "Epoch [32/100], Loss: 0.0991\n",
      "Epoch [33/100], Loss: 0.1159\n",
      "Epoch [34/100], Loss: 0.1096\n",
      "Epoch [35/100], Loss: 0.0705\n",
      "Epoch [36/100], Loss: 0.1445\n",
      "Epoch [37/100], Loss: 0.0989\n",
      "Epoch [38/100], Loss: 0.3503\n",
      "Epoch [39/100], Loss: 0.1232\n",
      "Epoch [40/100], Loss: 0.0593\n",
      "Epoch [41/100], Loss: 0.0432\n",
      "Epoch [42/100], Loss: 0.1434\n",
      "Epoch [43/100], Loss: 0.0658\n",
      "Epoch [44/100], Loss: 0.0999\n",
      "Epoch [45/100], Loss: 0.0869\n",
      "Epoch [46/100], Loss: 0.1964\n",
      "Epoch [47/100], Loss: 0.1849\n",
      "Epoch [48/100], Loss: 0.1342\n",
      "Epoch [49/100], Loss: 0.2522\n",
      "Epoch [50/100], Loss: 0.1454\n",
      "Epoch [51/100], Loss: 0.1295\n",
      "Epoch [52/100], Loss: 0.0700\n",
      "Epoch [53/100], Loss: 0.0824\n",
      "Epoch [54/100], Loss: 0.0772\n",
      "Epoch [55/100], Loss: 0.0653\n",
      "Epoch [56/100], Loss: 0.0451\n",
      "Epoch [57/100], Loss: 0.2243\n",
      "Epoch [58/100], Loss: 0.1284\n",
      "Epoch [59/100], Loss: 0.1758\n",
      "Epoch [60/100], Loss: 0.1110\n",
      "Epoch [61/100], Loss: 0.1395\n",
      "Epoch [62/100], Loss: 0.0565\n",
      "Epoch [63/100], Loss: 0.3556\n",
      "Epoch [64/100], Loss: 0.0720\n",
      "Epoch [65/100], Loss: 0.1787\n",
      "Epoch [66/100], Loss: 0.3046\n",
      "Epoch [67/100], Loss: 0.0630\n",
      "Epoch [68/100], Loss: 0.0481\n",
      "Epoch [69/100], Loss: 0.0705\n",
      "Epoch [70/100], Loss: 0.1124\n",
      "Epoch [71/100], Loss: 0.1102\n",
      "Epoch [72/100], Loss: 0.1041\n",
      "Epoch [73/100], Loss: 0.1237\n",
      "Epoch [74/100], Loss: 0.0750\n",
      "Epoch [75/100], Loss: 0.0706\n",
      "Epoch [76/100], Loss: 0.1673\n",
      "Epoch [77/100], Loss: 0.0371\n",
      "Epoch [78/100], Loss: 0.1188\n",
      "Epoch [79/100], Loss: 0.2494\n",
      "Epoch [80/100], Loss: 0.1425\n",
      "Epoch [81/100], Loss: 0.2019\n",
      "Epoch [82/100], Loss: 0.0512\n",
      "Epoch [83/100], Loss: 0.0608\n",
      "Epoch [84/100], Loss: 0.0747\n",
      "Epoch [85/100], Loss: 0.0378\n",
      "Epoch [86/100], Loss: 0.0627\n",
      "Epoch [87/100], Loss: 0.1467\n",
      "Epoch [88/100], Loss: 0.2834\n",
      "Epoch [89/100], Loss: 0.1771\n",
      "Epoch [90/100], Loss: 0.1994\n",
      "Epoch [91/100], Loss: 0.0365\n",
      "Epoch [92/100], Loss: 0.0383\n",
      "Epoch [93/100], Loss: 0.0858\n",
      "Epoch [94/100], Loss: 0.0480\n",
      "Epoch [95/100], Loss: 0.1332\n",
      "Epoch [96/100], Loss: 0.0600\n",
      "Epoch [97/100], Loss: 0.0643\n",
      "Epoch [98/100], Loss: 0.2668\n",
      "Epoch [99/100], Loss: 0.0785\n",
      "Epoch [100/100], Loss: 0.1347\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train_model(num_epochs):\n",
    "    data2vector.train()\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for data, targets in train_loader:\n",
    "            #data, targets = data.to(device), targets.to(device)\n",
    "            data, targets = data.to(device), targets.view(-1, 1).to(device)\n",
    "            #print(data.shape)\n",
    "            #print(targets.shape)\n",
    "            # Forward pass\n",
    "            vector = data2vector(data)\n",
    "            outputs = model(vector)\n",
    "            #loss = criterion(outputs.squeeze(), targets)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "train_model(num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d5e68b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 71.22%\n",
      "Precision of the model on the test set: 78.14%\n",
      "Recall of the model on the test set: 76.32%\n",
      "F1 of the model on the test set: 77.22%\n"
     ]
    }
   ],
   "source": [
    "data2vector.eval()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    tp = 0  # True Positives\n",
    "    fp = 0  # False Positives\n",
    "    fn = 0  # False Negatives\n",
    "\n",
    "    for data, targets in test_loader:\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        vector = data2vector(data)\n",
    "        outputs = model(vector)\n",
    "        predicted = (outputs.squeeze() > 0.5).float()\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "        tp += ((predicted == 1) & (targets == 1)).sum().item()\n",
    "        fp += ((predicted == 1) & (targets == 0)).sum().item()\n",
    "        fn += ((predicted == 0) & (targets == 1)).sum().item()\n",
    "\n",
    "    precision = 100 * tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = 100 * tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    print(f'Accuracy of the model on the test set: {100 * correct / total:.2f}%')\n",
    "    print(f'Precision of the model on the test set: {precision:.2f}%')\n",
    "    print(f'Recall of the model on the test set: {recall:.2f}%')\n",
    "    print(f'F1 of the model on the test set: {f1:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c2a9be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3697, 112])\n",
      "Confusion Matrix:\n",
      " [[229 115]\n",
      " [182 584]]\n",
      "\n",
      "Accuracy, Precision, Recall, F1:\n",
      "0.732432, 0.762402, 0.835479, 0.797270\n",
      "\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def run_model(model, train_X, train_y, postfix=''):\n",
    "    train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.3, random_state=42)\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_y = model.predict(val_X)\n",
    "    true_y = np.array(val_y)\n",
    "\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(true_y, pred_y).T)\n",
    "    accuracy = accuracy_score(true_y, pred_y)\n",
    "    precision = precision_score(true_y, pred_y)\n",
    "    recall = recall_score(true_y, pred_y)\n",
    "    f1 = f1_score(true_y, pred_y)\n",
    "    print('\\nAccuracy, Precision, Recall, F1:')\n",
    "    print(f'{accuracy:4f}, {precision:4f}, {recall:4f}, {f1:4f}\\n')\n",
    "    \n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=1,\n",
    "    reg_lambda=1,  # Default L2 regularization\n",
    "    reg_alpha=0   # Default L1 regularization\n",
    ")\n",
    "\n",
    "data2vector.eval()\n",
    "vector = data2vector(X_tensor.to(device))\n",
    "vector2 = vector.detach().cpu().numpy()\n",
    "print(vector.shape)\n",
    "run_model(xgb_clf, vector2, y, 'xgb')\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30d2bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
